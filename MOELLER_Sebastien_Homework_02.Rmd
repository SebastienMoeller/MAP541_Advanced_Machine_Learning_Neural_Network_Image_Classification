---
title: 'MAP 541 Homework 02'
author: 'Sebastien Moeller'
date: '14/03/2018'
output:
  html_document:
    fig_height: 4
    fig_width: 8
    number_sections: false
    toc: true
    toc_depth: 5
    toc_float: true
    theme: flatly
    highlight: haddock
# tan1
# darkunica
# deepskyblue3
# palevioletred
---

# Objectives
The purpose of this homework is to build an image recognition system, using transfer learning and fine-tuning based on pre tuned convolutional neural networks on ImageNet. (http://www.image-net.org/). I started with keras pre trained model (see for instance https://keras.rstudio.com/articles/applications.html).

# Exercise 1 -- Image Net
#### What is Image Net?
ImageNet is an image database organized according to the WordNet hierarchy (currently only the nouns), in which each node of the hierarchy is depicted by hundreds and thousands of images. Currently there is an average of over five hundred images per node.

#### ImageNet Cheese
How many different kinds of cheese can we find in ImageNet?

The query "cheese" matches 30 synsets.

#### Best classifier
What is the best classifier on ImageNet and what is its error rate?

<<<<<<< HEAD
The winner of the 2017 challenge used the following:

Adaptive attention[1] and deep combined convolutional models[2,3] are used for LOC task. 
Scale[4,5,6], context[7], sampling and deep combined convolutional networks[2,3] are considered for DET task. Object density estimation is used for score re-rank. With a mean AP of 0.731613.
=======
ImageNet has several competitions and measures the 'best' on several metrics such as Localization error, Classification error or mean AP depending on the competition task.
>>>>>>> origin/master

# Exercise 2 -- Build an image recognition system
Build an image recognition system for a 1000 everyday object categories (ImageNet ILSVRC) using Keras and TensorFlow.

```{r}
remove.packages('reticulate')
remove.packages('tensorflow')
remove.packages('keras')
```

```{r}
# require(devtools)
# install_github("rstudio/reticulate", force = TRUE)
# install_github("rstudio/tensorflow")
# install_github("rstudio/keras", force = TRUE)
```

```{r}
# require(devtools)
# install_github('rstudio/keras')
# library('keras')
# install_keras()
```
```{r}
# library(reticulate)
# conda_version()
```


#### Install keras
```{r, message = FALSE, warning = FALSE}
if (!require('pacman')) install.packages('pacman')

<<<<<<< HEAD
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes, EBImage)
theme_set(theme_solarized_2(light = FALSE))

# Keras needs to be install after loading the package
# if(!is_keras_abailable()){
=======


pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))

# Keras needs to be install after loading the package
# if(!is_keras_available()){
>>>>>>> origin/master
#   install_keras()
# }
```

#### ResNet50
Define ResNet50 as we model and check its architecture
```{r}
model0 <- application_resnet50(weights <- 'imagenet')
summary(model0)
```
The architecture of this model includes 25,636,712 parameters, of which only 53,120 are non-trainable by default.

#### Other pre-trained networks
What are the other pre trained networks available with keras? https://keras.rstudio.com/articles/applimonkeyions.html

The available networks currectly include:
Xception, VGG16, VGG19, ResNet50, InceptionV3, InceptionResNetV2, MobileNet, DenseNet, NASNet

#### Predicting an image content
open an image ('my_image.jpg' in the following example) representing a single object (if possible represented in ImageNet)
```{r}
img_path <- 'hot_air_balloon.jpeg'
img <- image_load(img_path, target_size = c(224,224))

<<<<<<< HEAD
# Reshape the image to fit the input format of wer model
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))

# Preprocess the input
x <- imagenet_preprocess_input(x)

# get the model predictions
=======
#Reshape the image to fit the input format of your model
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))


#Preprocess the input
x <- imagenet_preprocess_input(x)


#get the model predictions
>>>>>>> origin/master
preds <- model0 %>% predict(x)

# display the top 5 recognized objects. Do we find the one represented on our image?
imagenet_decode_predictions(preds, top <- 5)[[1]]
```
The NN recognized the hot air balloons as balloons, it recognized the lakeside and interpreted the light house as a church. Overall a good classification.

```{r}
img = readImage("hot_air_balloon.jpeg")
display(img, method = "raster")
```

# Exericse 3 -- Your Turn
### Binary Object Recognition
based on your previous work, build an binary object recognition (only two objects) by transfer learning and fine tuning.

#### Choose Two Classes
I chose cats and dogs.

#### Download images
Proceed adapting the code from https://keras.rstudio.com/articles/applications.html

I downloaded 50 images for each class and setup my data as follows:
```{r, message = FALSE, warning = FALSE}
original_dataset_dir <- 'data/original'
base_dir <- 'data/cats_and_dogs'
dir.create(base_dir)

train_dir <- file.path(base_dir, 'train')
dir.create(train_dir)
validation_dir <- file.path(base_dir, 'validation')
dir.create(validation_dir)
test_dir <- file.path(base_dir, 'test')
dir.create(test_dir)

train_cats_dir <- file.path(train_dir, 'cats')
dir.create(train_cats_dir)

train_dogs_dir <- file.path(train_dir, 'dogs')
dir.create(train_dogs_dir)

validation_cats_dir <- file.path(validation_dir, 'cats')
dir.create(validation_cats_dir)

validation_dogs_dir <- file.path(validation_dir, 'dogs')
dir.create(validation_dogs_dir)

test_cats_dir <- file.path(test_dir, 'cats')
dir.create(test_cats_dir)

test_dogs_dir <- file.path(test_dir, 'dogs')
dir.create(test_dogs_dir)

fnames <- paste0('cat.', 1:30, '.jpg')
file.copy(file.path(original_dataset_dir, fnames), 
          file.path(train_cats_dir)) 

fnames <- paste0('cat.', 31:40, '.jpg')
file.copy(file.path(original_dataset_dir, fnames), 
          file.path(validation_cats_dir))

fnames <- paste0('cat.', 41:50, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
          file.path(test_cats_dir))

fnames <- paste0('dog.', 1:30, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
          file.path(train_dogs_dir))

fnames <- paste0('dog.', 31:40, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
          file.path(validation_dogs_dir)) 

fnames <- paste0('dog.', 41:50, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
          file.path(test_dogs_dir))
```

Let's instantiate the VGG16 model.
```{r}
conv_base <- application_vgg16(
  weights = "imagenet",
  include_top = FALSE,
  input_shape = c(150, 150, 3)
)
```
We pass three arguments to the function:

-- `weights` specifies the weight checkpoint from which to initialize the model.

-- `include_top` refers to including (or not) the densely connected classifier on top of the network. By default, this densely connected classifier corresponds to the 1,000 classes from ImageNet. Because we intend to use our own densely connected classifier (with only two classes: cats and dogs), we do not need to include it.

-- `input_shape` is the shape of the image tensors that we will feed to the network. This argument is purely optional: if we do not pass it, the network will be able to process inputs of any size.

Here's the detail of the architecture of the VGG16 convolutional base. It's similar to the simple convnets.
```{r}
summary(conv_base)
```
At this point, there are two ways we could proceed:

-- Running the convolutional base over our dataset, recording its output to an array on disk, and then using this data as input to a standalone, densely connected classifier. This solution is fast and cheap to run, because it only requires running the convolutional base once for every input image, and the convolutional base is by far the most expensive part of the pipeline. But for the same reason, this technique will not allow us to use data augmentation.

-- Extending the model we have (conv_base) by adding dense layers on top, and running the whole thing end to end on the input data. This will allow us to use data augmentation, because every input image goes through the convolutional base every time it is seen by the model. But for the same reason, this technique is far more expensive than the first.

We will proceed with the second option. Note that this technique is very expensive and should only be attempted with a GPU for large sets.

Because models behave just like layers, we can add a model (like conv_base) to a sequential model just like we would add a layer.
```{r}
model <- keras_model_sequential() %>% 
  conv_base %>% 
  layer_flatten() %>% 
  layer_dense(units = 256, activation = "relu") %>% 
  layer_dense(units = 1, activation = "sigmoid")
```

This is what the model looks like now:
```{r}
summary(model)
```
As we can see, the convolutional base of VGG16 has 14,714,688 parameters, which is very large. The classifier we are adding on top has 2 million parameters.

Before we compile and train the model, it is very important to freeze the convolutional base. Freezing a layer or set of layers means preventing their weights from being updated during training. If we do not do this, then the representations that were previously learned by the convolutional base will be modified during training. Because the dense layers on top are randomly initialized, very large weight updates would be propagated through the network, effectively destroying the representations previously learned.

In Keras, we freeze a network using the `freeze_weights()` function:
```{r, eval = FALSE}
length(model$trainable_weights)
```


```{r, eval = FALSE}
freeze_weights(conv_base)
length(model$trainable_weights)
```
With this setup, only the weights from the two dense layers that we added will be trained. That is a total of four weight tensors: two per layer (the main weight matrix and the bias vector). Note that in order for these changes to take effect, we must first compile the model. If we ever modify weight trainability after compilation, we should then recompile the model, or these changes will be ignored.

#### USING DATA AUGMENTATION
Overfitting is caused by having too few samples to learn from, rendering us unable to train a model that can generalize to new data. Given infinite data, the model would be exposed to every possible aspect of the data distribution at hand: we would never overfit. Data augmentation takes the approach of generating more training data from existing training samples, by augmenting the samples via a number of random transformations that yield believable-looking images. The goal is that at training time, the model will never see the exact same picture twice. This helps expose the model to more aspects of the data and generalize better.

In Keras, this can be done by configuring a number of random transformations to be performed on the images read by an `image_data_generator()`
```{r, eval = FALSE}
train_datagen = image_data_generator(
  rescale = 1/255,
  rotation_range = 40,
  width_shift_range = 0.2,
  height_shift_range = 0.2,
  shear_range = 0.2,
  zoom_range = 0.2,
  horizontal_flip = TRUE,
  fill_mode = "nearest"
)
```

Now we can train our model using the image data generator:
```{r, eval = FALSE}
set.seed(100)
# Note that the validation data shouldn't be augmented!
test_datagen <- image_data_generator(rescale = 1/255)  

train_generator <- flow_images_from_directory(
  train_dir,                  # Target directory  
  train_datagen,              # Data generator
<<<<<<< HEAD
  target_size = c(150, 150),  # Resizes all images to 150 × 150
  batch_size = 5,
=======
  target_size = c(150, 150),  # Resizes all images to 150, 150
  batch_size = 20,
>>>>>>> origin/master
  class_mode = "binary"       # binary_crossentropy loss for binary labels
)

validation_generator <- flow_images_from_directory(
  validation_dir,
  test_datagen,
  target_size = c(150, 150),
  batch_size = 5,
  class_mode = "binary"
)

model %>% compile(
  loss = "binary_crossentropy",
  optimizer = optimizer_rmsprop(lr = 2e-5),
  metrics = c("accuracy")
)

set.seed(100)
history <- model %>% fit_generator(
  train_generator,
<<<<<<< HEAD
  steps_per_epoch = 6,
  epochs = 15,
=======
  # If we use no data augmentation we set steps = # samples = batch size = 38
  # We are using augmentation and can set it to a higher value
  steps_per_epoch = 45,
  # An epoch consists of going through all your training samples once. And one step/iteration refers to training over a single minibatch. So if you have 1,000,000 training samples and use a batch size of 100, one epoch will be equivalent to 10,000 steps, with 100 samples per step.
  epochs = 10,
>>>>>>> origin/master
  validation_data = validation_generator,
  # Our validation set consists of 6 images per class
  validation_steps = 6
)
```

<<<<<<< HEAD
```{r, eval = FALSE}
epochTimeline <- as.data.frame(history$metrics)
epochTimeline$epoch <- seq(1,15)
```

```{r, eval = FALSE}
p1 <- ggplot(epochTimeline) + 
=======

```{r}
modelTransfer <- as.data.frame(history$metrics)
modelTransfer$epoch <- seq(1,10)
```

```{r}
ggplot(modelTransfer) + 
>>>>>>> origin/master
  geom_point(aes(epoch, loss), size = 2, color = 'tan1') + 
  geom_line(aes(epoch, loss), color = 'tan1') +
  geom_point(aes(epoch, val_loss), size = 2, color = 'seagreen3') + 
  geom_line(aes(epoch, val_loss), color = 'seagreen3') +
  geom_hline(yintercept = epochTimeline$loss[15], color = 'tan1') +
  annotate('text', 0, epochTimeline$loss[15], vjust = -.4, hjust = 0, label = paste0(round(epochTimeline$loss[15], 4)), color = 'tan1') +
  geom_hline(yintercept = epochTimeline$val_loss[15], color = 'seagreen3') +
  annotate('text', 0, epochTimeline$val_loss[15], vjust = -.4, hjust = 0, label = paste0(round(epochTimeline$val_loss[15], 4)), color = 'seagreen3')

p1
ggsave("Transfer loss vs val_loss.png")
```
```{r}
<<<<<<< HEAD
img = readImage("Transfer loss vs val_loss.png")
display(img, method = "raster")
```


```{r, eval = FALSE}
p2 <- ggplot(epochTimeline) + 
=======
ggplot(modelTransfer) + 
>>>>>>> origin/master
  geom_line(aes(epoch, acc), color = 'tan1') +
  geom_point(aes(epoch, acc), size = 2, color = 'tan1') + 
  geom_line(aes(epoch, val_acc), color = 'seagreen3') +
  geom_point(aes(epoch, val_acc), size = 2, color = 'seagreen3') +
  geom_hline(yintercept = epochTimeline$acc[15], color = 'tan1') +
  annotate('text', 0, epochTimeline$acc[15], vjust = -.4, hjust = 0, label = paste0(round(epochTimeline$acc[15], 4)), color = 'tan1') +
  geom_hline(yintercept = epochTimeline$val_acc[15], color = 'seagreen3') +
  annotate('text', 0, epochTimeline$val_acc[15], vjust = -.4, hjust = 0, label = paste0(round(epochTimeline$val_acc[15], 4)), color = 'seagreen3')

p2
ggsave("Transfer acc vs val_acc.png")
```
<<<<<<< HEAD

```{r}
img = readImage("Transfer acc vs val_acc.png")
display(img, method = "raster")
```
Plotting the results of training the model, we reach a validation accuracy of `72%`.
=======
Plotting the results of training the model, we can see the validation accuracy. Because the validation set is so small the accuracy moves in large increments.
>>>>>>> origin/master

#### FINE-TUNING
Another widely used technique for model reuse, complementary to feature extraction, is fine-tuning. Fine-tuning consists of unfreezing a few of the top layers of a frozen model base used for feature extraction, and jointly training both the newly added part of the model (in this case, the fully connected classifier) and these top layers. This is called fine-tuning because it slightly adjusts the more abstract representations of the model being reused, in order to make them more relevant for the problem at hand.

As stated earlier, it is necessary to freeze the convolution base of VGG16 in order to be able to train a randomly initialized classifier on top. For the same reason, it is only possible to fine-tune the top layers of the convolutional base once the classifier on top has already been trained. If the classifier is not already trained, then the error signal propagating through the network during training will be too large, and the representations previously learned by the layers being fine-tuned will be destroyed. Thus the steps for fine-tuning a network are as follows:

-- Add our custom network on top of an already-trained base network.

-- Freeze the base network.

-- Train the part we added.

-- Unfreeze some layers in the base network.

-- Jointly train both these layers and the part we added.

We have already completed the first three steps when doing feature extraction. Let us proceed with step 4: Unfreeze conv_base and then freeze individual layers inside it.

As a reminder, this is what the convolutional base looks like:
```{r}
summary(conv_base)
```

We will fine-tune all of the layers from `block3_conv1` and on. Why not fine-tune the entire convolutional base? We could, but we need to consider the following:

-- Earlier layers in the convolutional base encode more-generic, reusable features, whereas layers higher up encode more-specialized features. It is more useful to fine-tune the more specialized features, because these are the ones that need to be repurposed on our new problem. There would be fast-decreasing returns in fine-tuning lower layers.

-- The more parameters we are training, the more we are at risk of overfitting. The convolutional base has 15 million parameters, so it would be risky to attempt to train it on our small dataset.

<<<<<<< HEAD
Thus, in this situation, it’s a good strategy to fine-tune only some of the layers in the convolutional base. Let’s set this up.
```{r, eval = FALSE}
=======
Thus, in this situation, it is a good strategy to fine-tune only some of the layers in the convolutional base. Let us set this up.
```{r}
>>>>>>> origin/master
unfreeze_weights(conv_base, from = 'block3_conv1')
```

```{r, eval = FALSE}
length(model$trainable_weights)
```
This version of the model has `22` trainable weights, a significant increase from the first model's `4`.

<<<<<<< HEAD
Now we can begin fine-tuning the network. we’ll do this with the RMSProp optimizer, using a very low learning rate. The reason for using a low learning rate is that we want to limit the magnitude of the modifications we make to the representations of the three layers we’re fine-tuning. Updates that are too large may harm these representations.
```{r, eval = FALSE}
=======
Now we can begin fine-tuning the network. we will do this with the RMSProp optimizer, using a very low learning rate. The reason for using a low learning rate is that we want to limit the magnitude of the modifications we make to the representations of the three layers we are fine-tuning. Updates that are too large may harm these representations.
```{r}
>>>>>>> origin/master
model %>% compile(
  loss = "binary_crossentropy",
  # low learning rate
  optimizer = optimizer_rmsprop(lr = 1e-5),
  metrics = c("accuracy")
)

set.seed(100)
history <- model %>% fit_generator(
  train_generator,
<<<<<<< HEAD
  steps_per_epoch = 6,
  epochs = 15,
=======
  # If we use no data augmentation we set steps = # samples = batch size = 38
  # We are using augmentation and can set it to a higher value
  steps_per_epoch = 45,
  # An epoch consists of going through all your training samples once. And one step/iteration refers to training over a single minibatch. So if you have 1,000,000 training samples and use a batch size of 100, one epoch will be equivalent to 10,000 steps, with 100 samples per step.
  epochs = 10,
>>>>>>> origin/master
  validation_data = validation_generator,
  # Our validation set consists of 6 images per class
  validation_steps = 6
)
```

<<<<<<< HEAD
```{r, eval = FALSE}
epochFinetune <- as.data.frame(history$metrics)
epochFinetune$epoch <- seq(1,15)
```

```{r, eval = FALSE}
p3 <- ggplot(epochFinetune) + 
=======
```{r}
modelFineTune <- as.data.frame(history$metrics)
modelFineTune$epoch <- seq(1,20)
```

```{r}
ggplot(modelFineTune) + 
>>>>>>> origin/master
  geom_point(aes(epoch, loss), size = 2, color = 'tan1') + 
  geom_line(aes(epoch, loss), color = 'tan1') +
  geom_point(aes(epoch, val_loss), size = 2, color = 'seagreen3') + 
  geom_line(aes(epoch, val_loss), color = 'seagreen3') +
  geom_hline(yintercept = epochFinetune$loss[15], color = 'tan1') +
  annotate('text', 0, epochFinetune$loss[15], vjust = -.4, hjust = 0, label = paste0(round(epochFinetune$loss[15], 4)), color = 'tan1') +
  geom_hline(yintercept = epochFinetune$val_loss[15], color = 'seagreen3') +
  annotate('text', 0, epochFinetune$val_loss[15], vjust = -.4, hjust = 0, label = paste0(round(epochFinetune$val_loss[15], 4)), color = 'seagreen3')

p3
ggsave("Fine Tune loss vs val_loss.png")
```

```{r}
<<<<<<< HEAD
img = readImage("Fine Tune loss vs val_loss.png")
display(img, method = "raster")
=======
ggplot(modelFineTune) + 
  geom_point(aes(epoch, acc), size = 2, color = 'tan1') + 
  geom_line(aes(epoch, acc), color = 'tan1') +
  geom_point(aes(epoch, val_acc), size = 2, color = 'seagreen3') + 
  geom_line(aes(epoch, val_acc), color = 'seagreen3')
```

```{r}
modelFineTune$acc[20]
>>>>>>> origin/master
```

```{r, eval = FALSE}
p4 <- ggplot(epochFinetune) + 
  geom_line(aes(epoch, acc), color = 'tan1') +
  geom_point(aes(epoch, acc), size = 2, color = 'tan1') + 
  geom_line(aes(epoch, val_acc), color = 'seagreen3') +
  geom_point(aes(epoch, val_acc), size = 2, color = 'seagreen3') +
  geom_hline(yintercept = epochFinetune$acc[15], color = 'tan1') +
  annotate('text', 0, epochFinetune$acc[15], vjust = -.4, hjust = 0, label = paste0(round(epochFinetune$acc[15], 4)), color = 'tan1') +
  geom_hline(yintercept = epochFinetune$val_acc[15], color = 'seagreen3') +
  annotate('text', 0, epochFinetune$val_acc[15], vjust = -.4, hjust = 0, label = paste0(round(epochFinetune$val_acc[15], 4)), color = 'seagreen3')

p4
ggsave("Fine Tune acc vs val_acc.png")
```

```{r}
img = readImage("Fine Tune acc vs val_acc.png")
display(img, method = "raster")
```

### Transfer Learning vs Fine Tuning
Is it better to do transfer learning and fine tuning or both?

Transfer learning was imperative to building our neural network. By using the VGG16 architecture's base, we were able to use previously trained layers as the base of our own classifier. We only needed to add our own layers on top to build a functioning classifier in a short amount of time.

Fine tuning on the other hand requires a base network to be unfrozen and modified at prefereably a low learning rate. Limiting the learning rate effectively limits the magnitude of the modifications we make to the representations of the layers we are fine-tuning. Updates that are too large may harm these representations. This is called fine-tuning because it slightly adjusts the more abstract representations of the model being reused, in order to make them more relevant for the problem at hand.

Only by using the two methods together do we achieve the best results. 

<<<<<<< HEAD

=======
Looking at the results of the learning, we focus on the outcome after 20 epochs.
```{r}
modelTransfer[20,]
```

```{r}
modelFineTune[20,]
```

```{r}

```
>>>>>>> origin/master

The validation accuraccy did not increase as the original model without fine tuning, managed to produce very accurate validation predictions, however the fine tuned model had 100% accuracy on the training data. This most likely implies overfitting but it is hard to tell with such a small training and validation set. The validation set is only 6 images per class meaning that marginal improvments are nearly unpercievable. This study and techniques could be more accurately understood with a larger sample size. A data set of 2000 images is considered small by some and we only used a total of 50 images per class.
