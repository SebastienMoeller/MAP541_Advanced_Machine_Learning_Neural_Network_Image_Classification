install_github('rstudio/reticulate')
require(devtools)
install_github('rstudio/reticulate')
install_github('rstudio/tensorflow')
install_github('rstudio/tensorflow')
install_github('rstudio/keras')
pacman::p_load(tensorflow, reticulate, keras)
model <- application_resnet50(weights <- 'imagenet')
is_keras_available()
if (!require('pacman')) install.packages('pacman')
# If the function 'is_keras_available()' returns FALSE install from github directly:
install.packages('devtools')
require(devtools)
install_github('rstudio/reticulate')
install_github('rstudio/tensorflow')
install_github('rstudio/keras')
pacman::p_load(tensorflow, reticulate, keras)
is_keras_available()
install.packages("devtools")
is_keras_available()
pacman::p_load(tensorflow, reticulate, keras)
is_keras_available()
pacman::p_load(tensorflow, reticulate, keras)
is_keras_available()
# If the function 'is_keras_available()' returns FALSE install from github directly:
uninstall('reticulate')
# If the function 'is_keras_available()' returns FALSE install from github directly:
remove.packages('reticulate', 'tensorflow', 'keras')
# If the function 'is_keras_available()' returns FALSE install from github directly:
remove.packages('reticulate')
remove.packages('tensorflow')
remove.packages('keras')
is_keras_available()
pacman::p_load(tensorflow, reticulate, keras)
is_keras_available()
# If the function 'is_keras_available()' returns FALSE install from github directly:
# remove.packages('reticulate')
# remove.packages('tensorflow')
# remove.packages('keras')
install.packages('devtools')
require(devtools)
install_github('rstudio/reticulate')
install_github('rstudio/tensorflow')
install_github('rstudio/keras')
pacman::p_load(tensorflow, reticulate, keras)
is_keras_available()
install_keras()
install_keras()
pacman::p_load(tensorflow, reticulate, keras)
install_keras()
is_keras_available()
model <- application_resnet50(weights <- 'imagenet')
summary(model)
img_path <- 'hot_air_balloon.jpeg'
img <- image_load(img_path, target_size <- c(224,224))
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- imagenet_preprocess_input(x)
preds <- model %>% predict(x)
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- imagenet_preprocess_input(x)
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- imagenet_preprocess_input(x)
img_path <- 'hot_air_balloon.jpeg'
img <- image_load(img_path, target_size <- c(224,224))
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- imagenet_preprocess_input(x)
original_dataset_dir <- 'data/original'
base_dir <- 'data/monkeys_and_dogs'
dir.create(base_dir)
train_dir <- file.path(base_dir, 'train')
dir.create(train_dir)
validation_dir <- file.path(base_dir, 'validation')
dir.create(validation_dir)
test_dir <- file.path(base_dir, 'test')
dir.create(test_dir)
train_monkeys_dir <- file.path(train_dir, 'monkeys')
dir.create(train_monkeys_dir)
train_dogs_dir <- file.path(train_dir, 'dogs')
dir.create(train_dogs_dir)
validation_monkeys_dir <- file.path(validation_dir, 'monkeys')
dir.create(validation_monkeys_dir)
validation_dogs_dir <- file.path(validation_dir, 'dogs')
dir.create(validation_dogs_dir)
test_monkeys_dir <- file.path(test_dir, 'monkeys')
dir.create(test_monkeys_dir)
test_dogs_dir <- file.path(test_dir, 'dogs')
dir.create(test_dogs_dir)
fnames <- paste0('monkey.', 1:15, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(train_monkeys_dir))
fnames <- paste0('monkey.', 16:19, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(validation_monkeys_dir))
fnames <- paste0('monkey.', 20:24, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(test_monkeys_dir))
fnames <- paste0('dog.', 1:15, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(train_dogs_dir))
fnames <- paste0('dog.', 16:19, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(validation_dogs_dir))
fnames <- paste0('dog.', 20:24, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(test_dogs_dir))
conv_base <- application_vgg16(
weights = "imagenet",
include_top = FALSE,
input_shape = c(150, 150, 3)
)
summary(conv_base)
model <- keras_model_sequential() %>%
conv_base %>%
layer_flatten() %>%
layer_dense(units = 256, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
summary(model)
length(model$trainable_weights)
freeze_weights(conv_base)
length(model$trainable_weights)
train_datagen = image_data_generator(
rescale = 1/255,
rotation_range = 40,
width_shift_range = 0.2,
height_shift_range = 0.2,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = TRUE,
fill_mode = "nearest"
)
# Note that the validation data shouldn't be augmented!
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
train_dir,                  # Target directory
train_datagen,              # Data generator
target_size = c(150, 150),  # Resizes all images to 150 Ã 150
batch_size = 20,
class_mode = "binary"       # binary_crossentropy loss for binary labels
)
validation_generator <- flow_images_from_directory(
validation_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 2e-5),
metrics = c("accuracy")
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 100,
epochs = 30,
validation_data = validation_generator,
validation_steps = 50
)
# Note that the validation data shouldn't be augmented!
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
train_dir,                  # Target directory
train_datagen,              # Data generator
target_size = c(150, 150),  # Resizes all images to 150 Ã 150
batch_size = 20,
class_mode = "binary"       # binary_crossentropy loss for binary labels
)
validation_generator <- flow_images_from_directory(
validation_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 2e-5),
metrics = c("accuracy")
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 100,
epochs = 5,
validation_data = validation_generator,
validation_steps = 50
)
# Note that the validation data shouldn't be augmented!
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
train_dir,                  # Target directory
train_datagen,              # Data generator
target_size = c(150, 150),  # Resizes all images to 150 Ã 150
batch_size = 20,
class_mode = "binary"       # binary_crossentropy loss for binary labels
)
validation_generator <- flow_images_from_directory(
validation_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 2e-5),
metrics = c("accuracy")
)
history <- model %>% fit_generator(
train_generator,
steps_per_epoch = 10,
epochs = 20,
validation_data = validation_generator,
validation_steps = 10
)
img_path <- 'hot_air_balloon.jpeg'
img <- image_load(img_path, target_size = c(224,224))
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- imagenet_preprocess_input(x)
preds <- model %>% predict(x)
model <- application_resnet50(weights <- 'imagenet')
summary(model)
img_path <- 'hot_air_balloon.jpeg'
img <- image_load(img_path, target_size = c(224,224))
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
x <- imagenet_preprocess_input(x)
preds <- model %>% predict(x)
imagenet_decode_predictions(preds, top <- 5)[[1]]
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_abailable()){
install_keras()
}
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
model0 <- application_resnet50(weights <- 'imagenet')
summary(model0)
summary(model0)
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
model0 <- application_resnet50(weights <- 'imagenet')
summary(model0)
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
model0 <- application_resnet50(weights <- 'imagenet')
summary(model0)
install_tensorflow(gpu = T)
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
install_tensorflow(gpu = T)
install_tensorflow(version = 'gpu')
# Using a GPU is much quicker than a CPU but may require a strong Nvidia GPU
install_tensorflow(version = 'gpu')
system2("C:/Python2/Scripts/activate r-tensorflow")
system2("C:/Windows/System32/Python2/Scripts/activate r-tensorflow")
system2("C:/Python27/Scripts/activate r-tensorflow")
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
# Using a GPU is much quicker than a CPU but may require a strong Nvidia GPU
#install_tensorflow(version = 'gpu')
model0 <- application_resnet50(weights <- 'imagenet')
summary(model0)
img_path <- 'hot_air_balloon.jpeg'
img <- image_load(img_path, target_size = c(224,224))
#Reshape the image to fit the input format of your model
x <- image_to_array(img)
x <- array_reshape(x, c(1, dim(x)))
#Preprocess the input
x <- imagenet_preprocess_input(x)
#get the model predictions
preds <- model0 %>% predict(x)
# display the top 5 recognized objects. Do we find the one represented on our image?
imagenet_decode_predictions(preds, top <- 5)[[1]]
original_dataset_dir <- 'data/original'
base_dir <- 'data/cats_and_dogs'
dir.create(base_dir)
train_dir <- file.path(base_dir, 'train')
dir.create(train_dir)
validation_dir <- file.path(base_dir, 'validation')
dir.create(validation_dir)
test_dir <- file.path(base_dir, 'test')
dir.create(test_dir)
train_monkeys_dir <- file.path(train_dir, 'cats')
dir.create(train_monkeys_dir)
train_dogs_dir <- file.path(train_dir, 'dogs')
dir.create(train_dogs_dir)
validation_monkeys_dir <- file.path(validation_dir, 'cats')
dir.create(validation_monkeys_dir)
validation_dogs_dir <- file.path(validation_dir, 'dogs')
dir.create(validation_dogs_dir)
test_monkeys_dir <- file.path(test_dir, 'cats')
dir.create(test_monkeys_dir)
test_dogs_dir <- file.path(test_dir, 'dogs')
dir.create(test_dogs_dir)
fnames <- paste0('cat.', 1:38, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(train_monkeys_dir))
fnames <- paste0('cat.', 39:44, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(validation_monkeys_dir))
fnames <- paste0('cat.', 45:50, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(test_monkeys_dir))
fnames <- paste0('dog.', 1:38, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(train_dogs_dir))
fnames <- paste0('dog.', 39:44, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(validation_dogs_dir))
fnames <- paste0('dog.', 45:50, '.jpg')
file.copy(file.path(original_dataset_dir, fnames),
file.path(test_dogs_dir))
conv_base <- application_vgg16(
weights = "imagenet",
include_top = FALSE,
input_shape = c(150, 150, 3)
)
summary(conv_base)
model <- keras_model_sequential() %>%
conv_base %>%
layer_flatten() %>%
layer_dense(units = 256, activation = "relu") %>%
layer_dense(units = 1, activation = "sigmoid")
summary(model)
length(model$trainable_weights)
freeze_weights(conv_base)
length(model$trainable_weights)
train_datagen = image_data_generator(
rescale = 1/255,
rotation_range = 40,
width_shift_range = 0.2,
height_shift_range = 0.2,
shear_range = 0.2,
zoom_range = 0.2,
horizontal_flip = TRUE,
fill_mode = "nearest"
)
# Note that the validation data shouldn't be augmented!
test_datagen <- image_data_generator(rescale = 1/255)
train_generator <- flow_images_from_directory(
train_dir,                  # Target directory
train_datagen,              # Data generator
target_size = c(150, 150),  # Resizes all images to 150, 150
batch_size = 20,
class_mode = "binary"       # binary_crossentropy loss for binary labels
)
validation_generator <- flow_images_from_directory(
validation_dir,
test_datagen,
target_size = c(150, 150),
batch_size = 20,
class_mode = "binary"
)
model %>% compile(
loss = "binary_crossentropy",
optimizer = optimizer_rmsprop(lr = 2e-5),
metrics = c("accuracy")
)
history <- model %>% fit_generator(
train_generator,
# If we use no data augmentation we set steps = # samples = batch size = 38
# We are using augmentation and can set it to a higher value
steps_per_epoch = 45,
# An epoch consists of going through all your training samples once. And one step/iteration refers to training over a single minibatch. So if you have 1,000,000 training samples and use a batch size of 100, one epoch will be equivalent to 10,000 steps, with 100 samples per step.
epochs = 10,
validation_data = validation_generator,
# Our validation set consists of 6 images per class
validation_steps = 6
)
modelTransfer <- as.data.frame(history$metrics)
modelTransfer$epoch <- seq(1,20)
modelTransfer <- as.data.frame(history$metrics)
modelTransfer$epoch <- seq(1,10)
ggplot(modelTransfer) +
geom_point(aes(epoch, loss), size = 2, color = 'tan1') +
geom_line(aes(epoch, loss), color = 'tan1') +
geom_point(aes(epoch, val_loss), size = 2, color = 'seagreen3') +
geom_line(aes(epoch, val_loss), color = 'seagreen3')
ggplot(modelTransfer) +
geom_line(aes(epoch, acc), color = 'tan1') +
geom_point(aes(epoch, acc), size = 2, color = 'tan1') +
geom_line(aes(epoch, val_acc), color = 'seagreen3') +
geom_point(aes(epoch, val_acc), size = 2, color = 'seagreen3')
summary(conv_base)
unfreeze_weights(conv_base, from = 'block3_conv1')
length(model$trainable_weights)
model %>% compile(
loss = "binary_crossentropy",
# low learning rate
optimizer = optimizer_rmsprop(lr = 1e-5),
metrics = c("accuracy")
)
history <- model %>% fit_generator(
train_generator,
# If we use no data augmentation we set steps = # samples = batch size = 38
# We are using augmentation and can set it to a higher value
steps_per_epoch = 45,
# An epoch consists of going through all your training samples once. And one step/iteration refers to training over a single minibatch. So if you have 1,000,000 training samples and use a batch size of 100, one epoch will be equivalent to 10,000 steps, with 100 samples per step.
epochs = 10,
validation_data = validation_generator,
# Our validation set consists of 6 images per class
validation_steps = 6
)
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
# Using a GPU is much quicker than a CPU but may require a strong Nvidia GPU
#install_tensorflow(version = 'gpu')
model0 <- application_resnet50(weights <- 'imagenet')
modelFineTune[20,]
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
if (!require('pacman')) install.packages('pacman')
pacman::p_load(tensorflow, reticulate, keras, ggplot2, ggthemes)
theme_set(theme_solarized_2(light = FALSE))
# Keras needs to be install after loading the package
if(!is_keras_available()){
install_keras()
}
is_keras_available()
install_keras()
keras::is_keras_available()
keras::install_keras()
